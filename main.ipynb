{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljr/.conda/envs/AI/lib/python3.9/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import spikingjelly\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time, datetime\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda import amp\n",
    "from spikingjelly.activation_based import neuron, encoding, functional, surrogate, layer\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from spikingjelly.clock_driven.neuron import MultiStepLIFNode\n",
    "from timm.layers import to_2tuple, trunc_normal_, DropPath\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.vision_transformer import _cfg\n",
    "from timm.models import create_model\n",
    "from functools import partial\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础部分： \n",
    "跑通SNN+MNIST，解释现有代码的原理，调整网络层及参数，观察效果；上限80分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST数据集获取\n",
    "# 设置数据转换，这里我们只进行归一化处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 下载并加载训练、测试数据集\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "trainloader_mnist = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=4)\n",
    "testloader_mnist = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全连接网络层\n",
    "# 一个隐藏层全连接网络\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, tau):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            layer.Flatten(),\n",
    "            layer.Linear(1 * 28 * 28, 10, bias=False),\n",
    "            neuron.LIFNode(tau=tau, surrogate_function=surrogate.ATan()),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer(x)\n",
    "\n",
    "# 卷积神经网络 \n",
    "class CSNN(nn.Module):\n",
    "    def __init__(self, T: int, channels: int, use_cupy=False):\n",
    "        super().__init__()\n",
    "        self.T = T  #SNN时间步长\n",
    "\n",
    "        self.conv_fc = nn.Sequential(\n",
    "        layer.Conv2d(1, channels, kernel_size=3, padding=1, bias=False),    #普通卷积层\n",
    "        layer.BatchNorm2d(channels),                                        #普通BatchNormalization\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),                 # IF脉冲节点\n",
    "        layer.MaxPool2d(2, 2),  # 14 * 14                                   # 最大池化\n",
    "\n",
    "        layer.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False), #普通卷积层\n",
    "        layer.BatchNorm2d(channels),                                        #普通BatchNormalization\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),                 #IF 脉冲节点\n",
    "        layer.MaxPool2d(2, 2),  # 7 * 7                                     # 最大池化\n",
    "\n",
    "        layer.Flatten(),\n",
    "        layer.Linear(channels * 7 * 7, channels * 4 * 4, bias=False),       #普通线性层\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),                 #IF 脉冲节点\n",
    "\n",
    "        layer.Linear(channels * 4 * 4, 10, bias=False),         \n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),\n",
    "        )\n",
    "\n",
    "        functional.set_step_mode(self, step_mode='m')                       #多步脉冲模式\n",
    "\n",
    "        if use_cupy:\n",
    "            functional.set_backend(self, backend='cupy')\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x.shape = [N, C, H, W]\n",
    "        x_seq = x.unsqueeze(0).repeat(self.T, 1, 1, 1, 1)  # [N, C, H, W] -> [T, N, C, H, W]  #将数据复制T份直接输入网络\n",
    "        x_seq = self.conv_fc(x_seq)\n",
    "        fr = x_seq.mean(0)\n",
    "        return fr\n",
    "    \n",
    "    def spiking_encoder(self):\n",
    "        return self.conv_fc[0:3] #脉冲节点即可将float输入编码为spike序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主干代码\n",
    "def main():\n",
    "    class parser:\n",
    "        def __init__(self):\n",
    "            self.T = 4\n",
    "            self.device='cuda'\n",
    "            self.epochs = 100\n",
    "            self.b = 32\n",
    "            self.j = 4\n",
    "            self.data_dir='./data'\n",
    "            self.out_dir='./logs'\n",
    "            self.resume = None\n",
    "            self.amp = False\n",
    "            self.opt = 'adam'\n",
    "            self.lr=1e-3\n",
    "            self.tau=2.0\n",
    "            self.channels = 128\n",
    "            self.cupy = False\n",
    "    '''        \n",
    "    parser = argparse.ArgumentParser(description='LIF MNIST Training')\n",
    "    parser.add_argument('-T', default=100, type=int, help='simulating time-steps')\n",
    "    parser.add_argument('-device', default='cuda:0', help='device')\n",
    "    parser.add_argument('-b', default=64, type=int, help='batch size')\n",
    "    parser.add_argument('-epochs', default=100, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('-j', default=4, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('-data-dir', type=str, help='root dir of MNIST dataset')\n",
    "    parser.add_argument('-out-dir', type=str, default='./logs', help='root dir for saving logs and checkpoint')\n",
    "    parser.add_argument('-resume', type=str, help='resume from the checkpoint path')\n",
    "    parser.add_argument('-amp', action='store_true', help='automatic mixed precision training')\n",
    "    parser.add_argument('-opt', type=str, choices=['sgd', 'adam'], default='adam', help='use which optimizer. SGD or Adam')\n",
    "    parser.add_argument('-momentum', default=0.9, type=float, help='momentum for SGD')\n",
    "    parser.add_argument('-lr', default=1e-3, type=float, help='learning rate')\n",
    "    parser.add_argument('-tau', default=2.0, type=float, help='parameter tau of LIF neuron')\n",
    "    '''\n",
    "    args = parser()\n",
    "    print(args)\n",
    "\n",
    "    net = CSNN(T=args.T, channels=args.channels, use_cupy=args.cupy)\n",
    "    print(net)\n",
    "    net = net.to(args.device)\n",
    "\n",
    "    start_epoch = 0\n",
    "    max_test_acc = -1\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "\n",
    "    out_dir = os.path.join(args.out_dir, f'T{args.T}_b{args.b}_{\"adam\"}_lr{args.lr}_c{args.channels}')\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        start_time = time.time()\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_samples = 0\n",
    "        for img, label in tqdm(trainloader_mnist):\n",
    "            optimizer.zero_grad()          #reset optimizer\n",
    "            img = img.to(args.device)\n",
    "            label = label.to(args.device)\n",
    "            label_onehot = F.one_hot(label, 10).float() #one-hot encoding the label to a vector\n",
    "\n",
    "\n",
    "            out_fr = net(img)\n",
    "            loss = F.mse_loss(out_fr, label_onehot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_samples += label.numel()\n",
    "            train_loss += loss.item() * label.numel()\n",
    "            train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "            functional.reset_net(net)\n",
    "\n",
    "        train_time = time.time()\n",
    "        train_speed = train_samples / (train_time - start_time)\n",
    "        train_loss /= train_samples\n",
    "        train_acc /= train_samples\n",
    "\n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('train_acc', train_acc, epoch)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        test_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for img, label in testloader_mnist:\n",
    "                img = img.to(args.device)\n",
    "                label = label.to(args.device)\n",
    "                label_onehot = F.one_hot(label, 10).float()\n",
    "                out_fr = net(img)\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "\n",
    "                test_samples += label.numel()\n",
    "                test_loss += loss.item() * label.numel()\n",
    "                test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "                functional.reset_net(net)\n",
    "        test_time = time.time()\n",
    "        test_speed = test_samples / (test_time - train_time)\n",
    "        test_loss /= test_samples\n",
    "        test_acc /= test_samples\n",
    "        writer.add_scalar('test_loss', test_loss, epoch)\n",
    "        writer.add_scalar('test_acc', test_acc, epoch)\n",
    "\n",
    "        save_max = False\n",
    "        if test_acc > max_test_acc:\n",
    "            max_test_acc = test_acc\n",
    "            save_max = True\n",
    "\n",
    "        checkpoint = {\n",
    "            'net': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'max_test_acc': max_test_acc\n",
    "        }\n",
    "\n",
    "        if save_max:\n",
    "            torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_max.pth'))\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_latest.pth'))\n",
    "\n",
    "        print(args)\n",
    "        print(out_dir)\n",
    "        print(f'epoch = {epoch}, train_loss ={train_loss: .4f}, train_acc ={train_acc: .4f}, test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}, max_test_acc ={max_test_acc: .4f}')\n",
    "        print(f'train speed ={train_speed: .4f} images/s, test speed ={test_speed: .4f} images/s')\n",
    "        print(f'escape time = {(datetime.datetime.now() + datetime.timedelta(seconds=(time.time() - start_time) * (args.epochs - epoch))).strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中级部分\n",
    "实现Transformer/Mamba等新兴网络结构+SNN+算法，在MNIST变种上取得较好效果，如Colored MNIST等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型spikeformer\n",
    "# __all__ = ['spikformer']\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1_linear = nn.Linear(in_features, hidden_features)\n",
    "        self.fc1_bn = nn.BatchNorm1d(hidden_features)\n",
    "        self.fc1_lif = MultiStepLIFNode(tau=2.0, backend='cupy')\n",
    "\n",
    "        self.fc2_linear = nn.Linear(hidden_features, out_features)\n",
    "        self.fc2_bn = nn.BatchNorm1d(out_features)\n",
    "        self.fc2_lif = MultiStepLIFNode(tau=2.0, backend='cupy')\n",
    "\n",
    "        self.c_hidden = hidden_features\n",
    "        self.c_output = out_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        T,B,N,C = x.shape\n",
    "        x_ = x.flatten(0, 1)\n",
    "        x = self.fc1_linear(x_)\n",
    "        x = self.fc1_bn(x.transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, self.c_hidden).contiguous()\n",
    "        x = self.fc1_lif(x)\n",
    "\n",
    "        x = self.fc2_linear(x.flatten(0,1))\n",
    "        x = self.fc2_bn(x.transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        x = self.fc2_lif(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SSA(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., sr_ratio=1):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = 0.125\n",
    "        self.q_linear = nn.Linear(dim, dim)\n",
    "        self.q_bn = nn.BatchNorm1d(dim)\n",
    "        self.q_lif = MultiStepLIFNode(tau=2.0, backend='cupy')\n",
    "\n",
    "        self.k_linear = nn.Linear(dim, dim)\n",
    "        self.k_bn = nn.BatchNorm1d(dim)\n",
    "        self.k_lif = MultiStepLIFNode(tau=2.0, backend='cupy')\n",
    "\n",
    "        self.v_linear = nn.Linear(dim, dim)\n",
    "        self.v_bn = nn.BatchNorm1d(dim)\n",
    "        self.v_lif = MultiStepLIFNode(tau=2.0, backend='cupy')\n",
    "        self.attn_lif = MultiStepLIFNode(tau=2.0, v_threshold=0.5, backend='cupy')\n",
    "\n",
    "        self.proj_linear = nn.Linear(dim, dim)\n",
    "        self.proj_bn = nn.BatchNorm1d(dim)\n",
    "        self.proj_lif = MultiStepLIFNode(tau=2.0, backend='cupy')\n",
    "\n",
    "    def forward(self, x):\n",
    "        T,B,N,C = x.shape\n",
    "\n",
    "        x_for_qkv = x.flatten(0, 1)  # TB, N, C\n",
    "        q_linear_out = self.q_linear(x_for_qkv)  # [TB, N, C]\n",
    "        q_linear_out = self.q_bn(q_linear_out. transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        q_linear_out = self.q_lif(q_linear_out)\n",
    "        q = q_linear_out.reshape(T, B, N, self.num_heads, C//self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n",
    "\n",
    "        k_linear_out = self.k_linear(x_for_qkv)\n",
    "        k_linear_out = self.k_bn(k_linear_out. transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        k_linear_out = self.k_lif(k_linear_out)\n",
    "        k = k_linear_out.reshape(T, B, N, self.num_heads, C//self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n",
    "\n",
    "        v_linear_out = self.v_linear(x_for_qkv)\n",
    "        v_linear_out = self.v_bn(v_linear_out. transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        v_linear_out = self.v_lif(v_linear_out)\n",
    "        v = v_linear_out.reshape(T, B, N, self.num_heads, C//self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        x = attn @ v\n",
    "        x = x.transpose(2, 3).reshape(T, B, N, C).contiguous()\n",
    "        x = self.attn_lif(x)\n",
    "        x = x.flatten(0, 1)\n",
    "        x = self.proj_lif(self.proj_bn(self.proj_linear(x).transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C))\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, sr_ratio=1):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = SSA(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                              attn_drop=attn_drop, proj_drop=drop, sr_ratio=sr_ratio)\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = MLP(in_features=dim, hidden_features=mlp_hidden_dim, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(x)\n",
    "        x = x + self.mlp(x)\n",
    "        return x\n",
    "\n",
    "class SPS(nn.Module):\n",
    "    def __init__(self, img_size_h=128, img_size_w=128, patch_size=4, in_channels=2, embed_dims=256):\n",
    "        super().__init__()\n",
    "        self.image_size = [img_size_h, img_size_w]\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        self.patch_size = patch_size\n",
    "        self.C = in_channels\n",
    "        self.H, self.W = self.image_size[0] // patch_size[0], self.image_size[1] // patch_size[1]\n",
    "        self.num_patches = self.H * self.W\n",
    "        self.proj_conv = nn.Conv2d(in_channels, embed_dims//8, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn = nn.BatchNorm2d(embed_dims//8)\n",
    "        self.proj_lif = MultiStepLIFNode(tau=2.0, backend='cupy')\n",
    "\n",
    "        self.proj_conv1 = nn.Conv2d(embed_dims//8, embed_dims//4, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn1 = nn.BatchNorm2d(embed_dims//4)\n",
    "        self.proj_lif1 = MultiStepLIFNode(tau=2.0, backend='cupy')\n",
    "\n",
    "        self.proj_conv2 = nn.Conv2d(embed_dims//4, embed_dims//2, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn2 = nn.BatchNorm2d(embed_dims//2)\n",
    "        self.proj_lif2 = MultiStepLIFNode(tau=2.0, backend='cupy')\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.proj_conv3 = nn.Conv2d(embed_dims//2, embed_dims, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn3 = nn.BatchNorm2d(embed_dims)\n",
    "        self.proj_lif3 = MultiStepLIFNode(tau=2.0, backend='cupy')\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.rpe_conv = nn.Conv2d(embed_dims, embed_dims, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.rpe_bn = nn.BatchNorm2d(embed_dims)\n",
    "        self.rpe_lif = MultiStepLIFNode(tau=2.0, backend='cupy')\n",
    "\n",
    "    def forward(self, x):\n",
    "        T, B, C, H, W = x.shape\n",
    "        x = self.proj_conv(x.flatten(0, 1)) # have some fire value\n",
    "        x = self.proj_bn(x).reshape(T, B, -1, H, W).contiguous()\n",
    "        x = self.proj_lif(x).flatten(0, 1).contiguous()\n",
    "\n",
    "        x = self.proj_conv1(x)\n",
    "        x = self.proj_bn1(x).reshape(T, B, -1, H, W).contiguous()\n",
    "        x = self.proj_lif1(x).flatten(0, 1).contiguous()\n",
    "\n",
    "        x = self.proj_conv2(x)\n",
    "        x = self.proj_bn2(x).reshape(T, B, -1, H, W).contiguous()\n",
    "        x = self.proj_lif2(x).flatten(0, 1).contiguous()\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.proj_conv3(x)\n",
    "        x = self.proj_bn3(x).reshape(T, B, -1, H//2, W//2).contiguous()\n",
    "        x = self.proj_lif3(x).flatten(0, 1).contiguous()\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        x_feat = x.reshape(T, B, -1, H//4, W//4).contiguous()\n",
    "        x = self.rpe_conv(x)\n",
    "        x = self.rpe_bn(x).reshape(T, B, -1, H//4, W//4).contiguous()\n",
    "        x = self.rpe_lif(x)\n",
    "        x = x + x_feat\n",
    "\n",
    "        x = x.flatten(-2).transpose(-1, -2)  # T,B,N,C\n",
    "        return x\n",
    "class Spikformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 img_size_h=128, img_size_w=128, patch_size=16, in_channels=2, num_classes=11,\n",
    "                 embed_dims=[64, 128, 256], num_heads=[1, 2, 4], mlp_ratios=[4, 4, 4], qkv_bias=False, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0., norm_layer=nn.LayerNorm,\n",
    "                 depths=[6, 8, 6], sr_ratios=[8, 4, 2], T = 4\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.T = T  # time step\n",
    "        self.num_classes = num_classes\n",
    "        self.depths = depths\n",
    "\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depths)]  # stochastic depth decay rule\n",
    "\n",
    "        patch_embed = SPS(img_size_h=img_size_h,\n",
    "                                 img_size_w=img_size_w,\n",
    "                                 patch_size=patch_size,\n",
    "                                 in_channels=in_channels,\n",
    "                                 embed_dims=embed_dims)\n",
    "\n",
    "        block = nn.ModuleList([Block(\n",
    "            dim=embed_dims, num_heads=num_heads, mlp_ratio=mlp_ratios, qkv_bias=qkv_bias,\n",
    "            qk_scale=qk_scale, drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[j],\n",
    "            norm_layer=norm_layer, sr_ratio=sr_ratios)\n",
    "            for j in range(depths)])\n",
    "\n",
    "        setattr(self, f\"patch_embed\", patch_embed)\n",
    "        setattr(self, f\"block\", block)\n",
    "\n",
    "        # classification head\n",
    "        self.head = nn.Linear(embed_dims, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def _get_pos_embed(self, pos_embed, patch_embed, H, W):\n",
    "        if H * W == self.patch_embed1.num_patches:\n",
    "            return pos_embed\n",
    "        else:\n",
    "            return F.interpolate(\n",
    "                pos_embed.reshape(1, patch_embed.H, patch_embed.W, -1).permute(0, 3, 1, 2),\n",
    "                size=(H, W), mode=\"bilinear\").reshape(1, -1, H * W).permute(0, 2, 1)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "\n",
    "        block = getattr(self, f\"block\")\n",
    "        patch_embed = getattr(self, f\"patch_embed\")\n",
    "\n",
    "        x = patch_embed(x)\n",
    "        for blk in block:\n",
    "            x = blk(x)\n",
    "        return x.mean(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x.unsqueeze(0)).repeat(self.T, 1, 1, 1, 1)\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x.mean(0))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取fashionmnist数据集\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "trainloader_fashionmnist = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "testloader_fashionmnist = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "Creating model\n",
      "number of params: 3351088\n",
      "Spikformer(\n",
      "  (patch_embed): SPS(\n",
      "    (proj_conv): Conv2d(1, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (proj_bn): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (proj_lif): MultiStepLIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (proj_conv1): Conv2d(18, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (proj_bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (proj_lif1): MultiStepLIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (proj_conv2): Conv2d(36, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (proj_bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (proj_lif2): MultiStepLIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (proj_conv3): Conv2d(72, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (proj_bn3): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (proj_lif3): MultiStepLIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (rpe_conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (rpe_bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rpe_lif): MultiStepLIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "  )\n",
      "  (block): ModuleList(\n",
      "    (0-11): 12 x Block(\n",
      "      (norm1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): SSA(\n",
      "        (q_linear): Linear(in_features=144, out_features=144, bias=True)\n",
      "        (q_bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (q_lif): MultiStepLIFNode(\n",
      "          v_threshold=1.0, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "          (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "        )\n",
      "        (k_linear): Linear(in_features=144, out_features=144, bias=True)\n",
      "        (k_bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (k_lif): MultiStepLIFNode(\n",
      "          v_threshold=1.0, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "          (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "        )\n",
      "        (v_linear): Linear(in_features=144, out_features=144, bias=True)\n",
      "        (v_bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (v_lif): MultiStepLIFNode(\n",
      "          v_threshold=1.0, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "          (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "        )\n",
      "        (attn_lif): MultiStepLIFNode(\n",
      "          v_threshold=0.5, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "          (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "        )\n",
      "        (proj_linear): Linear(in_features=144, out_features=144, bias=True)\n",
      "        (proj_bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (proj_lif): MultiStepLIFNode(\n",
      "          v_threshold=1.0, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "          (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "        )\n",
      "      )\n",
      "      (norm2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1_linear): Linear(in_features=144, out_features=576, bias=True)\n",
      "        (fc1_bn): BatchNorm1d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (fc1_lif): MultiStepLIFNode(\n",
      "          v_threshold=1.0, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "          (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "        )\n",
      "        (fc2_linear): Linear(in_features=576, out_features=144, bias=True)\n",
      "        (fc2_bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (fc2_lif): MultiStepLIFNode(\n",
      "          v_threshold=1.0, v_reset=0.0, detach_reset=False, tau=2.0, backend=cupy\n",
      "          (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=144, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:46<00:00,  8.28it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 19.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 0, train_loss = 0.0266, train_acc = 0.8310, test_loss = 0.0207, test_acc = 0.8656, max_test_acc = 0.8656\n",
      "train speed = 264.7986 images/s, test speed = 628.9756 images/s\n",
      "escape time = 2024-12-13 05:29:06\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:53<00:00,  8.05it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 20.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 1, train_loss = 0.0178, train_acc = 0.8856, test_loss = 0.0200, test_acc = 0.8740, max_test_acc = 0.8740\n",
      "train speed = 257.4521 images/s, test speed = 640.9259 images/s\n",
      "escape time = 2024-12-13 05:39:17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:46<00:00,  8.28it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 20.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 2, train_loss = 0.0156, train_acc = 0.9005, test_loss = 0.0157, test_acc = 0.8992, max_test_acc = 0.8992\n",
      "train speed = 265.0989 images/s, test speed = 651.0435 images/s\n",
      "escape time = 2024-12-13 05:27:50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:49<00:00,  8.18it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 19.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 3, train_loss = 0.0144, train_acc = 0.9088, test_loss = 0.0151, test_acc = 0.9019, max_test_acc = 0.9019\n",
      "train speed = 261.6123 images/s, test speed = 631.3635 images/s\n",
      "escape time = 2024-12-13 05:33:34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:47<00:00,  8.26it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 20.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 4, train_loss = 0.0138, train_acc = 0.9126, test_loss = 0.0159, test_acc = 0.9009, max_test_acc = 0.9019\n",
      "train speed = 264.2883 images/s, test speed = 643.3269 images/s\n",
      "escape time = 2024-12-13 05:28:56\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:42<00:00,  8.43it/s]\n",
      "100%|██████████| 313/313 [00:17<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 5, train_loss = 0.0132, train_acc = 0.9165, test_loss = 0.0135, test_acc = 0.9124, max_test_acc = 0.9124\n",
      "train speed = 269.6165 images/s, test speed = 570.0771 images/s\n",
      "escape time = 2024-12-13 05:25:22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:52<00:00,  8.06it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 18.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 6, train_loss = 0.0125, train_acc = 0.9220, test_loss = 0.0144, test_acc = 0.9077, max_test_acc = 0.9124\n",
      "train speed = 258.0311 images/s, test speed = 603.8726 images/s\n",
      "escape time = 2024-12-13 05:39:12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:43<00:00,  8.40it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 18.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 7, train_loss = 0.0121, train_acc = 0.9240, test_loss = 0.0135, test_acc = 0.9124, max_test_acc = 0.9124\n",
      "train speed = 268.6933 images/s, test speed = 593.8633 images/s\n",
      "escape time = 2024-12-13 05:25:12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:49<00:00,  8.18it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 20.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 8, train_loss = 0.0114, train_acc = 0.9284, test_loss = 0.0139, test_acc = 0.9123, max_test_acc = 0.9124\n",
      "train speed = 261.7815 images/s, test speed = 642.5877 images/s\n",
      "escape time = 2024-12-13 05:32:20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:51<00:00,  8.08it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 20.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 9, train_loss = 0.0109, train_acc = 0.9311, test_loss = 0.0131, test_acc = 0.9141, max_test_acc = 0.9141\n",
      "train speed = 258.6876 images/s, test speed = 646.5643 images/s\n",
      "escape time = 2024-12-13 05:36:46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:51<00:00,  8.11it/s]\n",
      "100%|██████████| 313/313 [00:17<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 10, train_loss = 0.0106, train_acc = 0.9333, test_loss = 0.0127, test_acc = 0.9174, max_test_acc = 0.9174\n",
      "train speed = 259.4227 images/s, test speed = 577.2096 images/s\n",
      "escape time = 2024-12-13 05:38:40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:45<00:00,  8.31it/s]\n",
      "100%|██████████| 313/313 [00:14<00:00, 20.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 11, train_loss = 0.0103, train_acc = 0.9345, test_loss = 0.0139, test_acc = 0.9119, max_test_acc = 0.9174\n",
      "train speed = 265.9163 images/s, test speed = 666.6310 images/s\n",
      "escape time = 2024-12-13 05:26:17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:47<00:00,  8.23it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 19.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 12, train_loss = 0.0100, train_acc = 0.9364, test_loss = 0.0129, test_acc = 0.9167, max_test_acc = 0.9174\n",
      "train speed = 263.2778 images/s, test speed = 635.5840 images/s\n",
      "escape time = 2024-12-13 05:30:43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:50<00:00,  8.12it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 18.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 13, train_loss = 0.0095, train_acc = 0.9398, test_loss = 0.0118, test_acc = 0.9245, max_test_acc = 0.9245\n",
      "train speed = 259.9011 images/s, test speed = 605.7105 images/s\n",
      "escape time = 2024-12-13 05:36:33\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:54<00:00,  8.00it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 18.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 14, train_loss = 0.0094, train_acc = 0.9414, test_loss = 0.0117, test_acc = 0.9272, max_test_acc = 0.9272\n",
      "train speed = 255.9359 images/s, test speed = 595.6098 images/s\n",
      "escape time = 2024-12-13 05:42:12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:53<00:00,  8.04it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 19.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 15, train_loss = 0.0090, train_acc = 0.9448, test_loss = 0.0120, test_acc = 0.9238, max_test_acc = 0.9272\n",
      "train speed = 257.1717 images/s, test speed = 625.8736 images/s\n",
      "escape time = 2024-12-13 05:39:02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:49<00:00,  8.17it/s]\n",
      "100%|██████████| 313/313 [00:14<00:00, 20.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 16, train_loss = 0.0087, train_acc = 0.9456, test_loss = 0.0112, test_acc = 0.9288, max_test_acc = 0.9288\n",
      "train speed = 261.3671 images/s, test speed = 668.6683 images/s\n",
      "escape time = 2024-12-13 05:32:37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:49<00:00,  8.18it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 19.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 17, train_loss = 0.0084, train_acc = 0.9479, test_loss = 0.0125, test_acc = 0.9190, max_test_acc = 0.9288\n",
      "train speed = 261.7944 images/s, test speed = 633.1802 images/s\n",
      "escape time = 2024-12-13 05:32:54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:47<00:00,  8.23it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 20.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 18, train_loss = 0.0081, train_acc = 0.9495, test_loss = 0.0116, test_acc = 0.9243, max_test_acc = 0.9288\n",
      "train speed = 263.3104 images/s, test speed = 653.6298 images/s\n",
      "escape time = 2024-12-13 05:30:23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:51<00:00,  8.09it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 19.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 19, train_loss = 0.0079, train_acc = 0.9511, test_loss = 0.0116, test_acc = 0.9274, max_test_acc = 0.9288\n",
      "train speed = 258.8702 images/s, test speed = 611.3963 images/s\n",
      "escape time = 2024-12-13 05:37:11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:50<00:00,  8.12it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 20, train_loss = 0.0077, train_acc = 0.9526, test_loss = 0.0115, test_acc = 0.9256, max_test_acc = 0.9288\n",
      "train speed = 259.7684 images/s, test speed = 625.9936 images/s\n",
      "escape time = 2024-12-13 05:35:34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:51<00:00,  8.08it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 19.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 21, train_loss = 0.0077, train_acc = 0.9527, test_loss = 0.0114, test_acc = 0.9262, max_test_acc = 0.9288\n",
      "train speed = 258.6414 images/s, test speed = 612.3367 images/s\n",
      "escape time = 2024-12-13 05:37:24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:50<00:00,  8.14it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 22, train_loss = 0.0074, train_acc = 0.9551, test_loss = 0.0110, test_acc = 0.9289, max_test_acc = 0.9289\n",
      "train speed = 260.4667 images/s, test speed = 616.6386 images/s\n",
      "escape time = 2024-12-13 05:35:29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:51<00:00,  8.11it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 19.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 23, train_loss = 0.0073, train_acc = 0.9554, test_loss = 0.0115, test_acc = 0.9276, max_test_acc = 0.9289\n",
      "train speed = 259.4467 images/s, test speed = 617.5101 images/s\n",
      "escape time = 2024-12-13 05:36:17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:49<00:00,  8.16it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 19.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 24, train_loss = 0.0070, train_acc = 0.9580, test_loss = 0.0122, test_acc = 0.9221, max_test_acc = 0.9289\n",
      "train speed = 261.2574 images/s, test speed = 619.7015 images/s\n",
      "escape time = 2024-12-13 05:34:09\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:56<00:00,  7.94it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 19.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 25, train_loss = 0.0069, train_acc = 0.9582, test_loss = 0.0107, test_acc = 0.9298, max_test_acc = 0.9298\n",
      "train speed = 253.9642 images/s, test speed = 638.3211 images/s\n",
      "escape time = 2024-12-13 05:42:13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:48<00:00,  8.22it/s]\n",
      "100%|██████████| 313/313 [00:15<00:00, 20.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 26, train_loss = 0.0066, train_acc = 0.9597, test_loss = 0.0116, test_acc = 0.9255, max_test_acc = 0.9298\n",
      "train speed = 262.8783 images/s, test speed = 650.8576 images/s\n",
      "escape time = 2024-12-13 05:31:30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:52<00:00,  8.08it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 27, train_loss = 0.0066, train_acc = 0.9610, test_loss = 0.0111, test_acc = 0.9290, max_test_acc = 0.9298\n",
      "train speed = 258.4127 images/s, test speed = 598.1776 images/s\n",
      "escape time = 2024-12-13 05:38:02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:54<00:00,  8.00it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 19.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.main.<locals>.parser object at 0x7049a2816d90>\n",
      "./logs/T4_b32_adam_lr0.001_c128_embed=144\n",
      "epoch = 28, train_loss = 0.0064, train_acc = 0.9611, test_loss = 0.0117, test_acc = 0.9280, max_test_acc = 0.9298\n",
      "train speed = 256.1343 images/s, test speed = 620.9286 images/s\n",
      "escape time = 2024-12-13 05:39:49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1138/1875 [02:19<01:30,  8.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 129\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain speed =\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_speed\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images/s, test speed =\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_speed\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images/s\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mescape time = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtimedelta(seconds\u001b[38;5;241m=\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mepoch)))\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 63\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     62\u001b[0m label_onehot \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(label, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;66;03m#one-hot encoding the label to a vector\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m out_fr \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(out_fr, label_onehot)\n\u001b[1;32m     65\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/AI/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/AI/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 223\u001b[0m, in \u001b[0;36mSpikformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    222\u001b[0m     x \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 223\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[0;32mIn[2], line 218\u001b[0m, in \u001b[0;36mSpikformer.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    216\u001b[0m x \u001b[38;5;241m=\u001b[39m patch_embed(x)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m block:\n\u001b[0;32m--> 218\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/AI/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/AI/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 97\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 97\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(x)\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/AI/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/AI/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 77\u001b[0m, in \u001b[0;36mSSA.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m v_linear_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_lif(v_linear_out)\n\u001b[1;32m     75\u001b[0m v \u001b[38;5;241m=\u001b[39m v_linear_out\u001b[38;5;241m.\u001b[39mreshape(T, B, N, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, C\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m---> 77\u001b[0m attn \u001b[38;5;241m=\u001b[39m (\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[1;32m     78\u001b[0m x \u001b[38;5;241m=\u001b[39m attn \u001b[38;5;241m@\u001b[39m v\n\u001b[1;32m     79\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(T, B, N, C)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练代码\n",
    "import logging\n",
    "from spikingjelly.clock_driven import functional\n",
    "# 获取根 logger\n",
    "# logging.getLogger(\"root\").setLevel(logging.ERROR)\n",
    "def main():\n",
    "    class parser:\n",
    "        def __init__(self):\n",
    "            self.T = 4\n",
    "            self.device='cuda'\n",
    "            self.epochs = 100\n",
    "            self.b = 32\n",
    "            self.j = 4\n",
    "            self.data_dir='./data'\n",
    "            self.out_dir='./logs'\n",
    "            self.resume = None\n",
    "            self.amp = False\n",
    "            self.lr=1e-3\n",
    "            self.tau=2.0\n",
    "            self.channels = 128\n",
    "            self.cupy = False\n",
    "    args = parser()\n",
    "    print(args)\n",
    "\n",
    "    net = Spikformer(\n",
    "        img_size_h=28, img_size_w=28,\n",
    "        patch_size=16, embed_dims=144, num_heads=12, mlp_ratios=4,\n",
    "        in_channels=1, num_classes=10, qkv_bias=False,\n",
    "        depths=12, sr_ratios=1,\n",
    "        T=args.T\n",
    "    )\n",
    "    print(\"Creating model\")\n",
    "    n_parameters = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    print(f\"number of params: {n_parameters}\")\n",
    "    print(net)\n",
    "    net = net.to(args.device)\n",
    "\n",
    "    start_epoch = 0\n",
    "    max_test_acc = -1\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "    out_dir = os.path.join(args.out_dir, f'T{args.T}_b{args.b}_{\"adam\"}_lr{args.lr}_c{args.channels}_embed=144')\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    writer = SummaryWriter(out_dir, purge_step=start_epoch)\n",
    "    with open(os.path.join(out_dir, 'args.txt'), 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write(str(args))\n",
    "        args_txt.write('\\n')\n",
    "        args_txt.write(' '.join(sys.argv))\n",
    "\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        start_time = time.time()\n",
    "        net.train()\n",
    "        train_loss, train_acc, train_samples = 0, 0, 0\n",
    "        for img, label in tqdm(trainloader_fashionmnist):\n",
    "            optimizer.zero_grad()          #reset optimizer\n",
    "            img = img.to(args.device)\n",
    "            label = label.to(args.device)\n",
    "            label_onehot = F.one_hot(label, 10).float() #one-hot encoding the label to a vector\n",
    "            out_fr = net(img)\n",
    "            loss = F.mse_loss(out_fr, label_onehot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_samples += label.numel()\n",
    "            train_loss += loss.item() * label.numel()\n",
    "            train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "            functional.reset_net(net)\n",
    "\n",
    "        train_time = time.time()\n",
    "        train_speed = train_samples / (train_time - start_time)\n",
    "        train_loss /= train_samples\n",
    "        train_acc /= train_samples\n",
    "\n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('train_acc', train_acc, epoch)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        test_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for img, label in tqdm(testloader_fashionmnist):\n",
    "                img = img.to(args.device)\n",
    "                label = label.to(args.device)\n",
    "                label_onehot = F.one_hot(label, 10).float()\n",
    "                out_fr = net(img)\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "\n",
    "                test_samples += label.numel()\n",
    "                test_loss += loss.item() * label.numel()\n",
    "                test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "                functional.reset_net(net)\n",
    "        test_time = time.time()\n",
    "        test_speed = test_samples / (test_time - train_time)\n",
    "        test_loss /= test_samples\n",
    "        test_acc /= test_samples\n",
    "        writer.add_scalar('test_loss', test_loss, epoch)\n",
    "        writer.add_scalar('test_acc', test_acc, epoch)\n",
    "\n",
    "        save_max = False\n",
    "        if test_acc > max_test_acc:\n",
    "            max_test_acc = test_acc\n",
    "            save_max = True\n",
    "\n",
    "        checkpoint = {\n",
    "            'net': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'max_test_acc': max_test_acc\n",
    "        }\n",
    "\n",
    "        if save_max:\n",
    "            torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_max.pth'))\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_latest.pth'))\n",
    "\n",
    "        print(args)\n",
    "        print(out_dir)\n",
    "        print(f'epoch = {epoch}, train_loss ={train_loss: .4f}, train_acc ={train_acc: .4f}, test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}, max_test_acc ={max_test_acc: .4f}')\n",
    "        print(f'train speed ={train_speed: .4f} images/s, test speed ={test_speed: .4f} images/s')\n",
    "        print(f'escape time = {(datetime.datetime.now() + datetime.timedelta(seconds=(time.time() - start_time) * (args.epochs - epoch))).strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
