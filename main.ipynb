{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spikingjelly\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time, datetime\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda import amp\n",
    "from spikingjelly.activation_based import neuron, encoding, functional, surrogate, layer\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from spikingjelly.clock_driven.neuron import MultiStepLIFNode\n",
    "from timm.layers import to_2tuple, trunc_normal_, DropPath\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.vision_transformer import _cfg\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础部分： \n",
    "跑通SNN+MNIST，解释现有代码的原理，调整网络层及参数，观察效果；上限80分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST数据集获取\n",
    "# 设置数据转换，这里我们只进行归一化处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 下载并加载训练、测试数据集\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "trainloader_mnist = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=4)\n",
    "testloader_mnist = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全连接网络层\n",
    "# 一个隐藏层全连接网络\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, tau):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            layer.Flatten(),\n",
    "            layer.Linear(1 * 28 * 28, 10, bias=False),\n",
    "            neuron.LIFNode(tau=tau, surrogate_function=surrogate.ATan()),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer(x)\n",
    "\n",
    "# 卷积神经网络 \n",
    "class CSNN(nn.Module):\n",
    "    def __init__(self, T: int, channels: int, use_cupy=False):\n",
    "        super().__init__()\n",
    "        self.T = T  #SNN时间步长\n",
    "\n",
    "        self.conv_fc = nn.Sequential(\n",
    "        layer.Conv2d(1, channels, kernel_size=3, padding=1, bias=False),    #普通卷积层\n",
    "        layer.BatchNorm2d(channels),                                        #普通BatchNormalization\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),                 # IF脉冲节点\n",
    "        layer.MaxPool2d(2, 2),  # 14 * 14                                   # 最大池化\n",
    "\n",
    "        layer.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False), #普通卷积层\n",
    "        layer.BatchNorm2d(channels),                                        #普通BatchNormalization\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),                 #IF 脉冲节点\n",
    "        layer.MaxPool2d(2, 2),  # 7 * 7                                     # 最大池化\n",
    "\n",
    "        layer.Flatten(),\n",
    "        layer.Linear(channels * 7 * 7, channels * 4 * 4, bias=False),       #普通线性层\n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),                 #IF 脉冲节点\n",
    "\n",
    "        layer.Linear(channels * 4 * 4, 10, bias=False),         \n",
    "        neuron.IFNode(surrogate_function=surrogate.ATan()),\n",
    "        )\n",
    "\n",
    "        functional.set_step_mode(self, step_mode='m')                       #多步脉冲模式\n",
    "\n",
    "        if use_cupy:\n",
    "            functional.set_backend(self, backend='cupy')\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x.shape = [N, C, H, W]\n",
    "        x_seq = x.unsqueeze(0).repeat(self.T, 1, 1, 1, 1)  # [N, C, H, W] -> [T, N, C, H, W]  #将数据复制T份直接输入网络\n",
    "        x_seq = self.conv_fc(x_seq)\n",
    "        fr = x_seq.mean(0)\n",
    "        return fr\n",
    "    \n",
    "    def spiking_encoder(self):\n",
    "        return self.conv_fc[0:3] #脉冲节点即可将float输入编码为spike序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主干代码\n",
    "def main():\n",
    "    class parser:\n",
    "        def __init__(self):\n",
    "            self.T = 4\n",
    "            self.device='cuda'\n",
    "            self.epochs = 100\n",
    "            self.b = 32\n",
    "            self.j = 4\n",
    "            self.data_dir='./data'\n",
    "            self.out_dir='./logs'\n",
    "            self.resume = None\n",
    "            self.amp = False\n",
    "            self.opt = 'adam'\n",
    "            self.lr=1e-3\n",
    "            self.tau=2.0\n",
    "            self.channels = 128\n",
    "            self.cupy = False\n",
    "    '''        \n",
    "    parser = argparse.ArgumentParser(description='LIF MNIST Training')\n",
    "    parser.add_argument('-T', default=100, type=int, help='simulating time-steps')\n",
    "    parser.add_argument('-device', default='cuda:0', help='device')\n",
    "    parser.add_argument('-b', default=64, type=int, help='batch size')\n",
    "    parser.add_argument('-epochs', default=100, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('-j', default=4, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('-data-dir', type=str, help='root dir of MNIST dataset')\n",
    "    parser.add_argument('-out-dir', type=str, default='./logs', help='root dir for saving logs and checkpoint')\n",
    "    parser.add_argument('-resume', type=str, help='resume from the checkpoint path')\n",
    "    parser.add_argument('-amp', action='store_true', help='automatic mixed precision training')\n",
    "    parser.add_argument('-opt', type=str, choices=['sgd', 'adam'], default='adam', help='use which optimizer. SGD or Adam')\n",
    "    parser.add_argument('-momentum', default=0.9, type=float, help='momentum for SGD')\n",
    "    parser.add_argument('-lr', default=1e-3, type=float, help='learning rate')\n",
    "    parser.add_argument('-tau', default=2.0, type=float, help='parameter tau of LIF neuron')\n",
    "    '''\n",
    "    args = parser()\n",
    "    print(args)\n",
    "\n",
    "    net = CSNN(T=args.T, channels=args.channels, use_cupy=args.cupy)\n",
    "    print(net)\n",
    "    net = net.to(args.device)\n",
    "\n",
    "    start_epoch = 0\n",
    "    max_test_acc = -1\n",
    "    \n",
    "    optimizer = None\n",
    "    if args.opt == 'sgd':\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    elif args.opt == 'adam':\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "    else:\n",
    "        raise NotImplementedError(args.opt)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "\n",
    "\n",
    "    out_dir = os.path.join(args.out_dir, f'T{args.T}_b{args.b}_{args.opt}_lr{args.lr}_c{args.channels}')\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        print(f'Mkdir {out_dir}.')\n",
    "\n",
    "    writer = SummaryWriter(out_dir, purge_step=start_epoch)\n",
    "    with open(os.path.join(out_dir, 'args.txt'), 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write(str(args))\n",
    "        args_txt.write('\\n')\n",
    "        args_txt.write(' '.join(sys.argv))\n",
    "\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        start_time = time.time()\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_samples = 0\n",
    "        for img, label in tqdm(trainloader_mnist):\n",
    "            optimizer.zero_grad()          #reset optimizer\n",
    "            img = img.to(args.device)\n",
    "            label = label.to(args.device)\n",
    "            label_onehot = F.one_hot(label, 10).float() #one-hot encoding the label to a vector\n",
    "\n",
    "\n",
    "            out_fr = net(img)\n",
    "            loss = F.mse_loss(out_fr, label_onehot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_samples += label.numel()\n",
    "            train_loss += loss.item() * label.numel()\n",
    "            train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "            functional.reset_net(net)\n",
    "\n",
    "        train_time = time.time()\n",
    "        train_speed = train_samples / (train_time - start_time)\n",
    "        train_loss /= train_samples\n",
    "        train_acc /= train_samples\n",
    "\n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('train_acc', train_acc, epoch)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        test_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for img, label in testloader_mnist:\n",
    "                img = img.to(args.device)\n",
    "                label = label.to(args.device)\n",
    "                label_onehot = F.one_hot(label, 10).float()\n",
    "                out_fr = net(img)\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "\n",
    "                test_samples += label.numel()\n",
    "                test_loss += loss.item() * label.numel()\n",
    "                test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "                functional.reset_net(net)\n",
    "        test_time = time.time()\n",
    "        test_speed = test_samples / (test_time - train_time)\n",
    "        test_loss /= test_samples\n",
    "        test_acc /= test_samples\n",
    "        writer.add_scalar('test_loss', test_loss, epoch)\n",
    "        writer.add_scalar('test_acc', test_acc, epoch)\n",
    "\n",
    "        save_max = False\n",
    "        if test_acc > max_test_acc:\n",
    "            max_test_acc = test_acc\n",
    "            save_max = True\n",
    "\n",
    "        checkpoint = {\n",
    "            'net': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'max_test_acc': max_test_acc\n",
    "        }\n",
    "\n",
    "        if save_max:\n",
    "            torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_max.pth'))\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_latest.pth'))\n",
    "\n",
    "        print(args)\n",
    "        print(out_dir)\n",
    "        print(f'epoch = {epoch}, train_loss ={train_loss: .4f}, train_acc ={train_acc: .4f}, test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}, max_test_acc ={max_test_acc: .4f}')\n",
    "        print(f'train speed ={train_speed: .4f} images/s, test speed ={test_speed: .4f} images/s')\n",
    "        print(f'escape time = {(datetime.datetime.now() + datetime.timedelta(seconds=(time.time() - start_time) * (args.epochs - epoch))).strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中级部分\n",
    "实现Transformer/Mamba等新兴网络结构+SNN+算法，在MNIST变种上取得较好效果，如Colored MNIST等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型spikeformer\n",
    "__all__ = ['spikformer']\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1_linear = nn.Linear(in_features, hidden_features)\n",
    "        self.fc1_bn = nn.BatchNorm1d(hidden_features)\n",
    "        self.fc1_lif = MultiStepLIFNode(tau=2.0, detach_reset=True, backend='cupy')\n",
    "\n",
    "        self.fc2_linear = nn.Linear(hidden_features, out_features)\n",
    "        self.fc2_bn = nn.BatchNorm1d(out_features)\n",
    "        self.fc2_lif = MultiStepLIFNode(tau=2.0, detach_reset=True, backend='cupy')\n",
    "\n",
    "        self.c_hidden = hidden_features\n",
    "        self.c_output = out_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        T,B,N,C = x.shape\n",
    "        x_ = x.flatten(0, 1)\n",
    "        x = self.fc1_linear(x_)\n",
    "        x = self.fc1_bn(x.transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, self.c_hidden).contiguous()\n",
    "        x = self.fc1_lif(x)\n",
    "\n",
    "        x = self.fc2_linear(x.flatten(0,1))\n",
    "        x = self.fc2_bn(x.transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        x = self.fc2_lif(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SSA(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., sr_ratio=1):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = 0.125\n",
    "        self.q_linear = nn.Linear(dim, dim)\n",
    "        self.q_bn = nn.BatchNorm1d(dim)\n",
    "        self.q_lif = MultiStepLIFNode(tau=2.0, detach_reset=True, backend='cupy')\n",
    "\n",
    "        self.k_linear = nn.Linear(dim, dim)\n",
    "        self.k_bn = nn.BatchNorm1d(dim)\n",
    "        self.k_lif = MultiStepLIFNode(tau=2.0, detach_reset=True, backend='cupy')\n",
    "\n",
    "        self.v_linear = nn.Linear(dim, dim)\n",
    "        self.v_bn = nn.BatchNorm1d(dim)\n",
    "        self.v_lif = MultiStepLIFNode(tau=2.0, detach_reset=True, backend='cupy')\n",
    "        self.attn_lif = MultiStepLIFNode(tau=2.0, v_threshold=0.5, detach_reset=True, backend='cupy')\n",
    "\n",
    "        self.proj_linear = nn.Linear(dim, dim)\n",
    "        self.proj_bn = nn.BatchNorm1d(dim)\n",
    "        self.proj_lif = MultiStepLIFNode(tau=2.0, detach_reset=True, backend='cupy')\n",
    "\n",
    "    def forward(self, x):\n",
    "        T,B,N,C = x.shape\n",
    "\n",
    "        x_for_qkv = x.flatten(0, 1)  # TB, N, C\n",
    "        q_linear_out = self.q_linear(x_for_qkv)  # [TB, N, C]\n",
    "        q_linear_out = self.q_bn(q_linear_out. transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        q_linear_out = self.q_lif(q_linear_out)\n",
    "        q = q_linear_out.reshape(T, B, N, self.num_heads, C//self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n",
    "\n",
    "        k_linear_out = self.k_linear(x_for_qkv)\n",
    "        k_linear_out = self.k_bn(k_linear_out. transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        k_linear_out = self.k_lif(k_linear_out)\n",
    "        k = k_linear_out.reshape(T, B, N, self.num_heads, C//self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n",
    "\n",
    "        v_linear_out = self.v_linear(x_for_qkv)\n",
    "        v_linear_out = self.v_bn(v_linear_out. transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C).contiguous()\n",
    "        v_linear_out = self.v_lif(v_linear_out)\n",
    "        v = v_linear_out.reshape(T, B, N, self.num_heads, C//self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        x = attn @ v\n",
    "        x = x.transpose(2, 3).reshape(T, B, N, C).contiguous()\n",
    "        x = self.attn_lif(x)\n",
    "        x = x.flatten(0, 1)\n",
    "        x = self.proj_lif(self.proj_bn(self.proj_linear(x).transpose(-1, -2)).transpose(-1, -2).reshape(T, B, N, C))\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, sr_ratio=1):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = SSA(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                              attn_drop=attn_drop, proj_drop=drop, sr_ratio=sr_ratio)\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = MLP(in_features=dim, hidden_features=mlp_hidden_dim, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(x)\n",
    "        x = x + self.mlp(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SPS(nn.Module):\n",
    "    def __init__(self, img_size_h=128, img_size_w=128, patch_size=4, in_channels=2, embed_dims=256):\n",
    "        super().__init__()\n",
    "        self.image_size = [img_size_h, img_size_w]\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        self.patch_size = patch_size\n",
    "        self.C = in_channels\n",
    "        self.H, self.W = self.image_size[0] // patch_size[0], self.image_size[1] // patch_size[1]\n",
    "        self.num_patches = self.H * self.W\n",
    "        self.proj_conv = nn.Conv2d(in_channels, embed_dims//8, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn = nn.BatchNorm2d(embed_dims//8)\n",
    "        self.proj_lif = MultiStepLIFNode(tau=2.0, detach_reset=True, backend='cupy')\n",
    "\n",
    "        self.proj_conv1 = nn.Conv2d(embed_dims//8, embed_dims//4, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn1 = nn.BatchNorm2d(embed_dims//4)\n",
    "        self.proj_lif1 = MultiStepLIFNode(tau=2.0, detach_reset=True, backend='cupy')\n",
    "\n",
    "        self.proj_conv2 = nn.Conv2d(embed_dims//4, embed_dims//2, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn2 = nn.BatchNorm2d(embed_dims//2)\n",
    "        self.proj_lif2 = MultiStepLIFNode(tau=2.0, detach_reset=True, backend='cupy')\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.proj_conv3 = nn.Conv2d(embed_dims//2, embed_dims, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.proj_bn3 = nn.BatchNorm2d(embed_dims)\n",
    "        self.proj_lif3 = MultiStepLIFNode(tau=2.0, detach_reset=True, backend='cupy')\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.rpe_conv = nn.Conv2d(embed_dims, embed_dims, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.rpe_bn = nn.BatchNorm2d(embed_dims)\n",
    "        self.rpe_lif = MultiStepLIFNode(tau=2.0, detach_reset=True, backend='cupy')\n",
    "\n",
    "    def forward(self, x):\n",
    "        T, B, C, H, W = x.shape\n",
    "        x = self.proj_conv(x.flatten(0, 1)) # have some fire value\n",
    "        x = self.proj_bn(x).reshape(T, B, -1, H, W).contiguous()\n",
    "        x = self.proj_lif(x).flatten(0, 1).contiguous()\n",
    "\n",
    "        x = self.proj_conv1(x)\n",
    "        x = self.proj_bn1(x).reshape(T, B, -1, H, W).contiguous()\n",
    "        x = self.proj_lif1(x).flatten(0, 1).contiguous()\n",
    "\n",
    "        x = self.proj_conv2(x)\n",
    "        x = self.proj_bn2(x).reshape(T, B, -1, H, W).contiguous()\n",
    "        x = self.proj_lif2(x).flatten(0, 1).contiguous()\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.proj_conv3(x)\n",
    "        x = self.proj_bn3(x).reshape(T, B, -1, H//2, W//2).contiguous()\n",
    "        x = self.proj_lif3(x).flatten(0, 1).contiguous()\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        x_feat = x.reshape(T, B, -1, H//4, W//4).contiguous()\n",
    "        x = self.rpe_conv(x)\n",
    "        x = self.rpe_bn(x).reshape(T, B, -1, H//4, W//4).contiguous()\n",
    "        x = self.rpe_lif(x)\n",
    "        x = x + x_feat\n",
    "\n",
    "        x = x.flatten(-2).transpose(-1, -2)  # T,B,N,C\n",
    "        return x\n",
    "\n",
    "\n",
    "class Spikformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 img_size_h=128, img_size_w=128, patch_size=16, in_channels=2, num_classes=11,\n",
    "                 embed_dims=[64, 128, 256], num_heads=[1, 2, 4], mlp_ratios=[4, 4, 4], qkv_bias=False, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0., norm_layer=nn.LayerNorm,\n",
    "                 depths=[6, 8, 6], sr_ratios=[8, 4, 2], T = 4\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.T = T  # time step\n",
    "        self.num_classes = num_classes\n",
    "        self.depths = depths\n",
    "\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depths)]  # stochastic depth decay rule\n",
    "\n",
    "        patch_embed = SPS(img_size_h=img_size_h,\n",
    "                                 img_size_w=img_size_w,\n",
    "                                 patch_size=patch_size,\n",
    "                                 in_channels=in_channels,\n",
    "                                 embed_dims=embed_dims)\n",
    "\n",
    "        block = nn.ModuleList([Block(\n",
    "            dim=embed_dims, num_heads=num_heads, mlp_ratio=mlp_ratios, qkv_bias=qkv_bias,\n",
    "            qk_scale=qk_scale, drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[j],\n",
    "            norm_layer=norm_layer, sr_ratio=sr_ratios)\n",
    "            for j in range(depths)])\n",
    "\n",
    "        setattr(self, f\"patch_embed\", patch_embed)\n",
    "        setattr(self, f\"block\", block)\n",
    "\n",
    "        # classification head\n",
    "        self.head = nn.Linear(embed_dims, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def _get_pos_embed(self, pos_embed, patch_embed, H, W):\n",
    "        if H * W == self.patch_embed1.num_patches:\n",
    "            return pos_embed\n",
    "        else:\n",
    "            return F.interpolate(\n",
    "                pos_embed.reshape(1, patch_embed.H, patch_embed.W, -1).permute(0, 3, 1, 2),\n",
    "                size=(H, W), mode=\"bilinear\").reshape(1, -1, H * W).permute(0, 2, 1)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "\n",
    "        block = getattr(self, f\"block\")\n",
    "        patch_embed = getattr(self, f\"patch_embed\")\n",
    "\n",
    "        x = patch_embed(x)\n",
    "        for blk in block:\n",
    "            x = blk(x)\n",
    "        return x.mean(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x.unsqueeze(0)).repeat(self.T, 1, 1, 1, 1)\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x.mean(0))\n",
    "        return x\n",
    "\n",
    "\n",
    "@register_model\n",
    "def spikformer(pretrained=False, **kwargs):\n",
    "    model = Spikformer(\n",
    "        # img_size_h=224, img_size_w=224,\n",
    "        # patch_size=16, embed_dims=768, num_heads=12, mlp_ratios=4,\n",
    "        # in_channels=3, num_classes=1000, qkv_bias=False,\n",
    "        # norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=12, sr_ratios=1,\n",
    "        **kwargs\n",
    "    )\n",
    "    model.default_cfg = _cfg()\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
